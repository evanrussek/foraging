{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "cd(\"/Users/evanrussek/foraging/\")\n",
        "\n",
        "using CSV\n",
        "using DataFrames\n",
        "using DataFramesMeta\n",
        "using CategoricalArrays\n",
        "using Gadfly\n",
        "# using MixedModels\n",
        "# using StatsBase\n",
        "using Statistics\n",
        "# import Cairo\n",
        "using Distributions\n",
        "using SpecialFunctions\n",
        "using StatsFuns\n",
        "using Optim\n",
        "using ForwardDiff\n",
        "using PyCall\n",
        "\n",
        "include(\"sim_lag_functions.jl\")\n",
        "include(\"sim_learn_funcs.jl\")\n",
        "\n",
        "# %% markdown\n",
        "\n",
        "hello\n",
        "\n",
        "# %% markdown\n",
        "\n",
        "\n",
        "\n",
        "# start reward was 120,90,60\n",
        "\n",
        "param_dict = Dict();\n",
        "param_dict[\"harvest_cost\"] = 1.;\n",
        "param_dict[\"travel_cost_easy\"] = 3.;\n",
        "param_dict[\"travel_cost_hard\"] = 5.;\n",
        "param_dict[\"r_hat_start_reward_weight\"] = 1. / 10;\n",
        "param_dict[\"r_hat_start_easy_weight\"] = 1.;\n",
        "param_dict[\"harvest_lag_hat_start\"] = 1.0; # don't fit this...\n",
        "param_dict[\"harvest_bias\"] = 0;\n",
        "param_dict[\"choice_beta\"] = 1.;\n",
        "param_dict[\"lag_beta\"] = 5.;\n",
        "param_dict[\"lr_R_hat_pre\"] = -2.9;\n",
        "param_dict[\"lr_harvest_lag_hat_pre\"] = -2.;\n",
        "transform_lr(param_dict[\"lr_R_hat_pre\"])\n",
        "\n",
        "param_dict\n",
        "\n",
        "sim_df = sim_forage_learn(param_dict);\n",
        "\n",
        "first(sim_df,6)\n",
        "\n",
        "\n",
        "plot(sim_df, x = :time, y = :reward_obs, xgroup = :travel_key_cond,ygroup = :start_reward, color = :start_reward,\n",
        "    Geom.subplot_grid(Geom.line))\n",
        "\n",
        "plot(sim_df, x = :time, y = :R_hat, xgroup = :travel_key_cond,\n",
        "    group = :trial_num, color = :start_reward, linestyle = :travel_key_cond,\n",
        "    Geom.subplot_grid(Geom.line))\n",
        "\n",
        "plot(sim_df, x = :time, y = :harvest_lag_hat, group = :trial_num, color = :start_reward,\n",
        " linestyle = :travel_key_cond, Geom.line)\n",
        "\n",
        "plot(sim_df, x = :time, y = :threshold, group = :trial_num, color = :start_reward,\n",
        "    linestyle = :travel_key_cond, Geom.line)\n",
        "\n",
        "### plot the exit threshold...\n",
        "make_exit_plot(sim_df)\n",
        "\n",
        "make_lag_plot(sim_df)\n",
        "\n",
        "\n",
        "########## likelihood function\n",
        "param_names = [];\n",
        "param_vals = Float64[];\n",
        "for (k,v) in param_dict\n",
        "    #println(k,v)\n",
        "    push!(param_names, k)\n",
        "    push!(param_vals, v)\n",
        "end\n",
        "print(param_names) # check that this matches the order in the likelihood function...\n",
        "include(\"sim_learn_funcs.jl\")\n",
        "\n",
        "# check how long different versions of like fun take\n",
        "@time nll1 = forage_learn_lik(param_vals, sim_df)\n",
        "\n",
        "@time nll2 = forage_learn_lik2(param_vals, sim_df)\n",
        "\n",
        "# check that function runs at start params\n",
        "nparam = length(param_dict)\n",
        "start_x = zeros(nparam);\n",
        "\n",
        "include(\"sim_learn_funcs.jl\")\n",
        "forage_learn_lik2(start_x, sim_df) # why is this a nan...\n",
        "# this can't be\n",
        "\n",
        "function relu_sm(b)\n",
        "    # makes minimum value .0001\n",
        "\tp=1/(1+exp(-100*(.0001 -b)))\n",
        "\treturn(p * .0001 + (1-p) * b)\n",
        "end\n",
        "\n",
        "\n",
        "# softmaximum function plot\n",
        "plot(relu_sm, -100., 40., Guide.ylabel(\"Soft Maximum\"), Guide.xlabel(\"Input\"))\n",
        "\n",
        "\n",
        "#\n",
        "cost_fun = (x) -> forage_learn_lik2(x,sim_df);\n",
        "\n",
        "bm = 3.;\n",
        "sp = (x) -> log(1. + exp(x))/bm + .0001\n",
        "sp2 = (x) -> x*erf(1.702*x)\n",
        "\n",
        "erf(-1)\n",
        "\n",
        "?erf\n",
        "\n",
        "C = 0;\n",
        "\n",
        "C_new = C < .0001 ? .001 : C\n",
        "\n",
        "plot([sp2, (x) -> x, (x) -> erf(x)], -100, 100)\n",
        "\n",
        "include(\"sim_learn_funcs.jl\")\n",
        "ForwardDiff.gradient(cost_fun,start_x)\n",
        "\n",
        "# o use python's scipy.optimize...\n",
        "#so = pyimport(\"scipy.optimize\")\n",
        "#@time a = so.minimize(cost_fun, start_x, method=\"L-BFGS-B\", jac = (x->ForwardDiff.gradient(cost_fun,x)))\n",
        "\n",
        "\n",
        "# julia optimize -- should be faster\n",
        "a = optimize((x) -> forage_learn_lik2(x,sim_df), start_x, LBFGS(); autodiff=:forward)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "a.minimum\n",
        "\n",
        "p_hat = a.minimizer\n",
        "\n",
        "# to dict...\n",
        "p_hat_dict = Dict()\n",
        "for j in 1:length(param_names)\n",
        "    p_hat_dict[param_names[j]] = p_hat[j]\n",
        "end\n",
        "\n",
        "sim_df_rec = sim_forage_learn(p_hat_dict);\n",
        "p_rec_choice = make_exit_plot(sim_df_rec)\n",
        "p_orig_choice = make_exit_plot(data)\n",
        "vstack([p_orig_choice; p_rec_choice])\n",
        "\n",
        "\n",
        "p_rec_lag = make_lag_plot(sim_df_rec)\n",
        "p_orig_lag = make_lag_plot(data)\n",
        "vstack([p_orig_lag; p_rec_lag])\n",
        "\n",
        "\n",
        "# is current param like better than orig param lik?\n",
        "new_lik = forage_learn_lik(p_hat,sim_df)\n",
        "# original values much worse...\n",
        "\n",
        "include(\"sim_learn_funcs.jl\")\n",
        "orig_lik = forage_learn_lik(param_vals,sim_df)\n",
        "\n",
        "harvest_df = @where(sim_df, :phase .== \"HARVEST\")\n",
        "findall(harvest_df[:choice] .== 2)\n",
        "\n",
        "# make a dictionary with simulated parameter value and recovered parameter value...\n",
        "\n",
        "original_val = zeros(length(param_dict));\n",
        "recovered_val = zeros(length(param_dict));\n",
        "param_name = [];\n",
        "i = 1;\n",
        "for (j,v) in param_dict\n",
        "    println(j)\n",
        "    push!(param_name,j);\n",
        "    original_val[i] = v;\n",
        "    recovered_val[i] = p_hat_dict[j]\n",
        "    global i = i+1;\n",
        "    #println(j,v)\n",
        "end\n",
        "fit_df = DataFrame(pname = param_name, original_val = original_val, recovered_val = recovered_val)\n",
        "\n",
        "\n",
        "params= start_x\n",
        "data = sim_df;"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Julia 1.3.1",
      "argv": [
        "/Applications/Julia-1.3.app/Contents/Resources/julia/bin/julia",
        "-i",
        "--startup-file=yes",
        "--color=yes",
        "--project=@.",
        "/Users/evanrussek/.julia/packages/IJulia/DrVMH/src/kernel.jl",
        "{connection_file}"
      ],
      "language": "julia",
      "env": {},
      "interrupt_mode": "signal",
      "name": "julia-1.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}